{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package versions:\n",
      "pandas==0.25.2\n",
      "numpy==1.17.3\n",
      "torch==1.3.1\n",
      "matplotlib==3.1.1\n",
      "Package git commit hashes:\n",
      "pandas==0efc71b53f019c6c5a8da7a38e08646ca75c17d9\n",
      "numpy==ff3df08438d570b0ccdda3f8a008278d8a4ad394\n",
      "torch==ee77ccbb6da4e2efd83673e798acf7081bc03564\n",
      "matplotlib==bed022902c04af827d24d86d161eaf401041dbe3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "\n",
    "import utils\n",
    "import model\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "print(\"Package versions:\")\n",
    "print(\"pandas==%s\" % pd.__version__)\n",
    "print(\"numpy==%s\" % np.__version__)\n",
    "print(\"torch==%s\" % torch.__version__)\n",
    "print(\"matplotlib==%s\" % matplotlib.__version__)\n",
    "\n",
    "print(\"Package git commit hashes:\")\n",
    "print(\"pandas==%s\" % pd.__git_version__)\n",
    "print(\"numpy==%s\" % np.__git_revision__)\n",
    "print(\"torch==%s\" % torch.version.git_version)\n",
    "print(\"matplotlib==%s\" % json.loads(matplotlib._version.version_json)['full-revisionid'])\n",
    "\n",
    "seed = 42\n",
    "device = utils.DEVICE\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "device = utils.DEVICE\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed to 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# batch_size = 985\n",
    "batch_size = 984\n",
    "hidden_dim = 51\n",
    "\n",
    "# Load and preprocess data.\n",
    "df = pd.read_csv(\"data/scheduling_data_out_ab_nginx.csv\")\n",
    "df = utils.preprocess_data(df=df)\n",
    "data = df.to_numpy()\n",
    "data_dim = data.shape[1]\n",
    "total = data.shape[0]\n",
    "remainder = total % batch_size\n",
    "data = data[:total - remainder, :]\n",
    "data = data.reshape(batch_size, data_dim, -1)  # TODO: Stop hard-coding this.\n",
    "data = np.transpose(data, axes=(0, 2, 1))\n",
    "\n",
    "assert not df.isnull().values.any(), \"Dataset contains a NaN value. Aborting.\"\n",
    "\n",
    "assert df.apply(lambda s: pd.to_numeric(s, errors='coerce').notnull().all()).all(), \\\n",
    "    \"At least 1 value in the dataframe is non-numeric.\"\n",
    "\n",
    "train_x, train_y, test_x, test_y = utils.make_training_and_testing_set(data, percent_train=97.0)\n",
    "train_x, train_y, test_x, test_y = train_x.to(device), train_y.to(device), test_x.to(device), test_y.to(device)\n",
    "\n",
    "# build the model\n",
    "seq = model.Sequence2(in_dim=data_dim, out_dim=data_dim, hidden_dim=hidden_dim).to(device)\n",
    "seq.double()\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "# use LBFGS as optimizer since we can load the whole data to train\n",
    "optimizer = optim.LBFGS(seq.parameters(), lr=0.8)\n",
    "\n",
    "# begin to train\n",
    "for i in range(15):\n",
    "    print('STEP: ', i)\n",
    "\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        out = seq(train_x).to(device)\n",
    "        _loss = criterion(out, train_y).to(device)\n",
    "        print('loss:', _loss.item())\n",
    "        _loss.backward()\n",
    "        return _loss\n",
    "\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    # begin to predict, no need to track gradient here\n",
    "    with torch.no_grad():\n",
    "        future = 1000\n",
    "        pred = seq(test_x, future=future)\n",
    "        loss = criterion(pred[:, :-future], test_y)\n",
    "        print('test loss:', loss.item())\n",
    "        y = pred.cpu().numpy()\n",
    "    # draw the result\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.title('Predict future values for time sequences\\n(Dashlines are predicted values)', fontsize=30)\n",
    "    plt.xlabel('x', fontsize=20)\n",
    "    plt.ylabel('y', fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "\n",
    "\n",
    "    def draw(yi, color):\n",
    "        plt.plot(np.arange(train_x.size(1)), yi[:train_x.size(1)], color, linewidth=2.0)\n",
    "        plt.plot(np.arange(train_x.size(1), train_x.size(1) + future), yi[train_x.size(1):], color + ':',\n",
    "                 linewidth=2.0)\n",
    "\n",
    "\n",
    "    draw(y[0], 'r')\n",
    "    draw(y[1], 'g')\n",
    "    draw(y[2], 'b')\n",
    "    plt.savefig('predict%d.pdf' % i)\n",
    "    plt.close()\n",
    "\n",
    "make_dot(pred, seq.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lkp_project)",
   "language": "python",
   "name": "lkp_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
